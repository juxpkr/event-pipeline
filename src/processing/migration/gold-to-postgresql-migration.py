import os
import sys
import logging

# Airflowì—ì„œ ì‹¤í–‰í•  ë•Œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
sys.path.append("/opt/airflow")

from src.utils.spark_builder import get_spark_session

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def main():
    """dbt Gold í…Œì´ë¸”ì„ PostgreSQLë¡œ Migration"""

    # Spark ì„¸ì…˜ ìƒì„±
    spark = get_spark_session(
        "Gold_To_PostgreSQL_Migration", "spark://spark-master:7077"
    )

    try:
        # dbtë¡œ ë§Œë“  gold table ì½ê¸°
        logger.info("ğŸ“¥ Reading Gold table from Hive Metastore...")
        # ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ì‹œë„
        try:
            gold_df = spark.sql("SELECT * FROM gold.gdelt_microbatch_country_analysis")
        except Exception as e:
            logger.info(f"ì²« ë²ˆì§¸ ë°©ë²• ì‹¤íŒ¨, ë‹¤ë¥¸ ë°©ë²• ì‹œë„: {e}")
            try:
                gold_df = spark.table("gold.gdelt_microbatch_country_analysis")
            except Exception as e2:
                logger.info(f"ë‘ ë²ˆì§¸ ë°©ë²•ë„ ì‹¤íŒ¨: {e2}")
                # ì§ì ‘ Delta íŒŒì¼ ì½ê¸° ì‹œë„
                gold_df = spark.read.format("delta").load(
                    "s3a://gold/gdelt_microbatch_country_analysis"
                )

        record_count = gold_df.count()
        logger.info(f"ğŸ“Š Found {record_count} records in Gold table")

        if record_count == 0:
            logger.warning("âš ï¸ No data found in Gold table!")
            return

        # PostgreSQL ì—°ê²° ì •ë³´ (.envì—ì„œ ê°€ì ¸ì˜´)
        pg_url = f"jdbc:postgresql://{os.getenv('POSTGRES_HOST')}:{os.getenv('POSTGRES_PORT')}/{os.getenv('POSTGRES_DB')}"

        # PostgreSQLë¡œ ì €ì¥
        logger.info("ğŸ’¾ Writing to PostgreSQL...")
        (
            gold_df.write.format("jdbc")
            .option("url", pg_url)
            .option("dbtable", "gdelt_country_analysis")
            .option("user", os.getenv("POSTGRES_USER"))
            .option("password", os.getenv("POSTGRES_PASSWORD"))
            .option("driver", "org.postgresql.Driver")
            .mode("overwrite")
            .save()
        )

        logger.info(
            f"âœ… Migration completed! {record_count} records written to PostgreSQL"
        )

    except Exception as e:
        logger.error(f"âŒ Migration failed: {e}")

    finally:
        spark.stop()


if __name__ == "__main__":
    main()
