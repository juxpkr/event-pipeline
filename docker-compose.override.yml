services:
  zookeeper:
    image: ${ZOOKEEPER_IMAGE}
    container_name: zookeeper
    ports:
      - "2181:2181"
    networks:
      - data-network
    env_file:
      - ./.env
      - ./config/zookeeper/zookeeper.env
    healthcheck:
      test: [ "CMD-SHELL", "echo 'ruok' | nc localhost 2181" ]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 30s

  kafka:
    build:
      context: .
      dockerfile: ./kafka/Dockerfile
      args:
        - KAFKA_IMAGE=${KAFKA_IMAGE}
        - JMX_PROMETHEUS_JAVAAGENT_VERSION=${JMX_PROMETHEUS_JAVAAGENT_VERSION}
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "9999:9999" # JMX RMI port
      - "9404:9404" # Prometheus HTTP metrics port
    networks:
      - data-network
    env_file:
      - ./.env
      - ./config/kafka/kafka.env
    command: >
      bash -c " export KAFKA_OPTS='-javaagent:/opt/kafka/libs/jmx_prometheus_javaagent-1.4.0.jar=9404:/opt/kafka/config/kafka_jmx_config.yml' && /etc/confluent/docker/run "
    volumes:
      - ./monitoring/jmx/kafka_jmx_config.yml:/opt/kafka/config/kafka_jmx_config.yml
    healthcheck:
      test: [ "CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list" ]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 60s

  kafka-setup:
    image: ${KAFKA_IMAGE}
    container_name: kafka-setup
    depends_on:
      - kafka
    networks:
      - data-network
    volumes:
      - ./config/kafka:/config
      - ./scripts/wait-for-it.sh:/usr/local/bin/wait-for-it.sh:ro
    entrypoint: [ "/usr/local/bin/wait-for-it.sh", "kafka:9092", "-t", "60", "--", "sh", "/config/setup-topics.sh" ]

  minio:
    image: ${MINIO_IMAGE}
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    networks:
      - data-network
    env_file:
      - ./.env
      - ./config/minio/minio.env
    command: minio server /data --console-address ":9001"
    volumes:
      - minio-data:/data

  minio-setup:
    image: minio/mc
    container_name: minio-setup
    depends_on:
      - minio
    networks:
      - data-network
    env_file:
      - ./.env
      - ./config/minio/minio.env
    volumes:
      - ./config/minio:/config
      - ./scripts/wait-for-it.sh:/usr/local/bin/wait-for-it.sh:ro
    entrypoint: [ "/usr/local/bin/wait-for-it.sh", "minio:9000", "-t", "30", "--", "/bin/sh", "/config/setup-minio.sh" ]

  spark-master:
    build:
      context: .
      dockerfile: ./spark-base/Dockerfile
      args:
        - SPARK_VERSION=${SPARK_VERSION}
        - HADOOP_VERSION=${HADOOP_VERSION}
        - SPARK_TGZ_URL=${SPARK_TGZ_URL}
        - COMMON_JARS_ZIP_URL=${COMMON_JARS_ZIP_URL}
        - SPARK_JARS_ZIP_URL=${SPARK_JARS_ZIP_URL}
        - DELTA_SPARK_VERSION=${DELTA_SPARK_VERSION}
        - HADOOP_AWS_VERSION=${HADOOP_AWS_VERSION}
        - AWS_SDK_VERSION=${AWS_SDK_VERSION}
        - POSTGRESQL_JDBC_VERSION=${POSTGRESQL_JDBC_VERSION}
        - KAFKA_CLIENTS_VERSION=${KAFKA_CLIENTS_VERSION}
        - SCALA_VERSION=${SCALA_VERSION}
        - COMMONS_POOL2_VERSION=${COMMONS_POOL2_VERSION}
        - LZ4_JAVA_VERSION=${LZ4_JAVA_VERSION}
        - COMMONS_LOGGING_VERSION=${COMMONS_LOGGING_VERSION}
        - PROMETHEUS_SIMPLECLIENT_VERSION=${PROMETHEUS_SIMPLECLIENT_VERSION}
    container_name: spark-master
    entrypoint: [ "/bin/sh", "-c" ]
    command:
      - |
        wait-for-it.sh kafka:9092 -t 60 -- echo "✅ Kafka is ready for Master."
        wait-for-it.sh minio:9000 -t 30 -- echo "✅ MinIO is ready for Master."
        exec /usr/bin/tini -- /opt/entrypoint.sh master
    user: root # 나중에 배포할때 수정
    depends_on:
      - minio
      - kafka
      - kafka-setup
    ports:
      - "8081:8080"
      - "7077:7077"
      - "8090:8090"
    networks:
      - data-network
    volumes:
      - .:/app
      - ./spark-ivy-cache:/home/spark/.ivy2
      - spark-jars:/opt/spark/jars
    env_file:
      - ./.env
      - ./config/spark/spark.env
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:8080 || exit 1" ]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 30s

  spark-worker:
    build:
      context: .
      dockerfile: ./spark-base/Dockerfile
      args:
        - SPARK_VERSION=${SPARK_VERSION}
        - HADOOP_VERSION=${HADOOP_VERSION}
        - SPARK_TGZ_URL=${SPARK_TGZ_URL}
        - COMMON_JARS_ZIP_URL=${COMMON_JARS_ZIP_URL}
        - SPARK_JARS_ZIP_URL=${SPARK_JARS_ZIP_URL}
        - DELTA_SPARK_VERSION=${DELTA_SPARK_VERSION}
        - HADOOP_AWS_VERSION=${HADOOP_AWS_VERSION}
        - AWS_SDK_VERSION=${AWS_SDK_VERSION}
        - POSTGRESQL_JDBC_VERSION=${POSTGRESQL_JDBC_VERSION}
        - KAFKA_CLIENTS_VERSION=${KAFKA_CLIENTS_VERSION}
        - SCALA_VERSION=${SCALA_VERSION}
        - COMMONS_POOL2_VERSION=${COMMONS_POOL2_VERSION}
        - LZ4_JAVA_VERSION=${LZ4_JAVA_VERSION}
        - COMMONS_LOGGING_VERSION=${COMMONS_LOGGING_VERSION}
        - PROMETHEUS_SIMPLECLIENT_VERSION=${PROMETHEUS_SIMPLECLIENT_VERSION}
    container_name: spark-worker
    entrypoint: [ "/bin/sh", "-c" ]
    command:
      - |
        wait-for-it.sh spark-master:7077 -t 60 -- echo "✅ Spark Master is ready for Worker."
        exec /usr/bin/tini -- /opt/entrypoint.sh worker spark://spark-master:7077
    user: root # 나중에 배포할때 수정
    networks:
      - data-network
    depends_on:
      - spark-master
    ports:
      - "8091:8091"
    volumes:
      - .:/app
      - ./spark-ivy-cache:/home/spark/.ivy2
      - spark-jars:/opt/spark/jars
    env_file:
      - ./.env

  spark-thrift-server:
    build:
      context: .
      dockerfile: ./spark-base/Dockerfile
      args:
        - SPARK_VERSION=${SPARK_VERSION}
        - HADOOP_VERSION=${HADOOP_VERSION}
        - SPARK_TGZ_URL=${SPARK_TGZ_URL}
        - COMMON_JARS_ZIP_URL=${COMMON_JARS_ZIP_URL}
        - SPARK_JARS_ZIP_URL=${SPARK_JARS_ZIP_URL}
        - DELTA_SPARK_VERSION=${DELTA_SPARK_VERSION}
        - HADOOP_AWS_VERSION=${HADOOP_AWS_VERSION}
        - AWS_SDK_VERSION=${AWS_SDK_VERSION}
        - POSTGRESQL_JDBC_VERSION=${POSTGRESQL_JDBC_VERSION}
        - KAFKA_CLIENTS_VERSION=${KAFKA_CLIENTS_VERSION}
        - SCALA_VERSION=${SCALA_VERSION}
        - COMMONS_POOL2_VERSION=${COMMONS_POOL2_VERSION}
        - LZ4_JAVA_VERSION=${LZ4_JAVA_VERSION}
        - COMMONS_LOGGING_VERSION=${COMMONS_LOGGING_VERSION}
        - PROMETHEUS_SIMPLECLIENT_VERSION=${PROMETHEUS_SIMPLECLIENT_VERSION}
    container_name: spark-thrift-server
    entrypoint: [ "/bin/sh", "-c" ]
    command:
      - |
        wait-for-it.sh spark-master:7077 -t 60 -- echo "✅ Spark Master is ready."
        wait-for-it.sh hive-metastore:9083 -t 60 -- echo "✅ Hive Metastore is ready."
        exec /usr/bin/tini -- /opt/entrypoint.sh thrift-binary
    user: root # 나중에 배포할때 수정
    env_file:
      - ./.env
    networks:
      - data-network
    depends_on:
      - spark-master
      - hive-metastore
    ports:
      - "10001:10001" # dbt 연결용
      - "4040:4040" # Spark Application UI
      - "4041:4041"
    volumes:
      - .:/app
      - ./spark-ivy-cache:/home/spark/.ivy2
      - spark-jars:/opt/spark/jars

  hive-metastore:
    build:
      context: .
      dockerfile: ./hive/Dockerfile
      args:
        POSTGRESQL_JDBC_VERSION: ${POSTGRESQL_JDBC_VERSION}
        HIVE_JARS_ZIP_URL: ${HIVE_JARS_ZIP_URL}
    container_name: hive-metastore
    entrypoint: [ "wait-for-it.sh", "postgres:5432", "-t", "60", "--", "wait-for-it.sh", "minio:9000", "-t", "30", "--", "bash", "/custom-entrypoint.sh" ]
    networks:
      - data-network
    ports:
      - "9083:9083"
    depends_on:
      - postgres
      - minio-setup
    env_file:
      - ./.env
      - ./config/hive-metastore/hive-metastore.env
    environment:
      # 이 서비스의 역할을 metastore로 지정한다
      - SERVICE_NAME=metastore
      # Metastore가 사용할 데이터베이스 정보를 알려준다.
      - DB_DRIVER=postgres
      - METASTORE_DB_HOSTNAME=postgres
      - METASTORE_DB_PORT=5432
      - METASTORE_DB_NAME=metastore_db
      - METASTORE_DB_USER=${POSTGRES_USER}
      - METASTORE_DB_PASSWORD=${POSTGRES_PASSWORD}
    healthcheck:
      test: [ "CMD-SHELL", "netstat -tuln | grep 9083 || exit 1" ]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 30s
    restart: unless-stopped

  postgres:
    image: ${POSTGRES_IMAGE}
    container_name: postgres
    env_file:
      - ./.env
      - ./config/postgres/postgres.env
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./config/postgres/init-postgres.sh:/docker-entrypoint-initdb.d/init-postgres.sh:ro
      - ./config/postgres/healthcheck.sh:/usr/local/bin/healthcheck.sh:ro
    ports:
      - "5432:5432"
    networks:
      - data-network
    healthcheck:
      test: [ "CMD-SHELL", "healthcheck.sh" ]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 45s

  airflow-init:
    build:
      context: .
      dockerfile: ./airflow/Dockerfile
      args:
        - SPARK_VERSION=${SPARK_VERSION}
        - HADOOP_VERSION=${HADOOP_VERSION}
        - SPARK_TGZ_URL=${SPARK_TGZ_URL}
        - COMMON_JARS_ZIP_URL=${COMMON_JARS_ZIP_URL}
        - SPARK_JARS_ZIP_URL=${SPARK_JARS_ZIP_URL}
        - DELTA_SPARK_VERSION=${DELTA_SPARK_VERSION}
        - HADOOP_AWS_VERSION=${HADOOP_AWS_VERSION}
        - AWS_SDK_VERSION=${AWS_SDK_VERSION}
        - POSTGRESQL_JDBC_VERSION=${POSTGRESQL_JDBC_VERSION}
        - KAFKA_CLIENTS_VERSION=${KAFKA_CLIENTS_VERSION}
        - SCALA_VERSION=${SCALA_VERSION}
        - COMMONS_POOL2_VERSION=${COMMONS_POOL2_VERSION}
        - LZ4_JAVA_VERSION=${LZ4_JAVA_VERSION}
        - COMMONS_LOGGING_VERSION=${COMMONS_LOGGING_VERSION}
        - PROMETHEUS_SIMPLECLIENT_VERSION=${PROMETHEUS_SIMPLECLIENT_VERSION}
    container_name: airflow-init
    networks:
      - data-network
    depends_on:
      - postgres
    env_file:
      - ./.env
      - ./config/airflow/airflow.env
    volumes:
      - ./config/airflow/init-airflow.sh:/opt/airflow/init-airflow.sh:ro
    entrypoint: [ "wait-for-it.sh", "postgres:5432", "-t", "60", "--", "sh", "/opt/airflow/init-airflow.sh" ]

  airflow-webserver:
    build:
      context: .
      dockerfile: ./airflow/Dockerfile
      args:
        - SPARK_VERSION=${SPARK_VERSION}
        - HADOOP_VERSION=${HADOOP_VERSION}
        - SPARK_TGZ_URL=${SPARK_TGZ_URL}
        - COMMON_JARS_ZIP_URL=${COMMON_JARS_ZIP_URL}
        - SPARK_JARS_ZIP_URL=${SPARK_JARS_ZIP_URL}
        - DELTA_SPARK_VERSION=${DELTA_SPARK_VERSION}
        - HADOOP_AWS_VERSION=${HADOOP_AWS_VERSION}
        - AWS_SDK_VERSION=${AWS_SDK_VERSION}
        - POSTGRESQL_JDBC_VERSION=${POSTGRESQL_JDBC_VERSION}
        - KAFKA_CLIENTS_VERSION=${KAFKA_CLIENTS_VERSION}
        - SCALA_VERSION=${SCALA_VERSION}
        - COMMONS_POOL2_VERSION=${COMMONS_POOL2_VERSION}
        - LZ4_JAVA_VERSION=${LZ4_JAVA_VERSION}
        - COMMONS_LOGGING_VERSION=${COMMONS_LOGGING_VERSION}
        - PROMETHEUS_SIMPLECLIENT_VERSION=${PROMETHEUS_SIMPLECLIENT_VERSION}
    container_name: airflow-webserver
    user: "${AIRFLOW_UID:-50000}"
    depends_on:
      - airflow-init
      - kafka-setup
    ports:
      - "8082:8080" # <--- Spark와 충돌하지 않도록 8082 포트 사용
    networks:
      - data-network
    env_file:
      - ./.env
      - ./config/airflow/airflow.env
    volumes:
      - ./dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - ./config:/opt/airflow/config
      - ./.secrets:/opt/airflow/.secrets
      - ./.env:/opt/airflow/.env
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - .:/app
    command: webserver

  airflow-scheduler:
    build:
      context: .
      dockerfile: ./airflow/Dockerfile
      args:
        - SPARK_VERSION=${SPARK_VERSION}
        - HADOOP_VERSION=${HADOOP_VERSION}
        - SPARK_TGZ_URL=${SPARK_TGZ_URL}
        - COMMON_JARS_ZIP_URL=${COMMON_JARS_ZIP_URL}
        - SPARK_JARS_ZIP_URL=${SPARK_JARS_ZIP_URL}
        - DELTA_SPARK_VERSION=${DELTA_SPARK_VERSION}
        - HADOOP_AWS_VERSION=${HADOOP_AWS_VERSION}
        - AWS_SDK_VERSION=${AWS_SDK_VERSION}
        - POSTGRESQL_JDBC_VERSION=${POSTGRESQL_JDBC_VERSION}
        - KAFKA_CLIENTS_VERSION=${KAFKA_CLIENTS_VERSION}
        - SCALA_VERSION=${SCALA_VERSION}
        - COMMONS_POOL2_VERSION=${COMMONS_POOL2_VERSION}
        - LZ4_JAVA_VERSION=${LZ4_JAVA_VERSION}
        - COMMONS_LOGGING_VERSION=${COMMONS_LOGGING_VERSION}
        - PROMETHEUS_SIMPLECLIENT_VERSION=${PROMETHEUS_SIMPLECLIENT_VERSION}
    container_name: airflow-scheduler
    user: "${AIRFLOW_UID:-50000}"
    networks:
      - data-network
    depends_on:
      - airflow-init
      - kafka-setup
    env_file:
      - ./.env
      - ./config/airflow/airflow.env
    volumes:
      - ./dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - ./config:/opt/airflow/config
      - ./.secrets:/opt/airflow/.secrets
      - ./.env:/opt/airflow/.env
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - .:/app
    command: scheduler

  jupyter-lab:
    build: .
    container_name: jupyter-lab
    depends_on:
      - spark-master
    ports:
      - "8888:8888"
    env_file:
      - ./.env
      - ./config/jupyter/jupyter.env
    volumes:
      - .:/app
      - spark-jars:/opt/spark/jars
    networks:
      - data-network

  dbt:
    build:
      context: ./transforms
    container_name: dbt
    env_file:
      - ./.env
      - ./config/dbt/dbt.env
    networks:
      - data-network
    volumes:
      - ./transforms:/app
    # 이 컨테이너는 시작된 후, tail 명령을 실행하며 계속 살아있게 된다.
    command: [ "tail", "-f", "/dev/null" ]

  superset:
    image: ${SUPERSET_IMAGE}
    container_name: superset
    depends_on:
      - postgres
    ports:
      - "8088:8088"
    networks:
      - data-network
    env_file:
      - ./.env
      - ./config/superset/superset.env
    volumes:
      - ./superset:/app/superset_home
      - ./config/superset:/config
      - ./scripts/wait-for-it.sh:/usr/local/bin/wait-for-it.sh:ro
    entrypoint: [ "/usr/local/bin/wait-for-it.sh", "postgres:5432", "-t", "60", "--", "sh", "/config/init-superset.sh" ]

  prometheus:
    image: ${PROMETHEUS_IMAGE}
    container_name: prometheus
    depends_on:
      - spark-master
      - spark-worker
      - kafka
    ports:
      - "${PROMETHEUS_PORT}:9090"
    networks:
      - data-network
    volumes:
      - ./monitoring/prometheus:/etc/prometheus
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--storage.tsdb.retention.time=15d'
      - '--web.enable-lifecycle'

  grafana:
    image: ${GRAFANA_IMAGE}
    container_name: grafana
    ports:
      - "${GRAFANA_PORT}:3000"
    networks:
      - data-network
    env_file:
      - ./.env
      - ./config/grafana/grafana.env
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana:/etc/grafana/provisioning
      - ./scripts/wait-for-it.sh:/usr/local/bin/wait-for-it.sh:ro
    depends_on:
      - prometheus
    entrypoint: [ "/usr/local/bin/wait-for-it.sh", "prometheus:9090", "-t", "60", "--", "/run.sh" ]

  spark-custom-exporter:
    build: ./spark-exporter
    container_name: spark-custom-exporter
    networks:
      - data-network
    ports:
      - "9191:9191"
    env_file:
      - ./.env
    depends_on:
      - spark-master
      - redis
    volumes:
      - ./spark-exporter:/app

  redis:
    image: redis:7-alpine
    container_name: redis
    ports:
      - "6379:6379"
    networks:
      - data-network
    volumes:
      - redis-data:/data
    command: redis-server --save 60 1 --loglevel warning
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  minio-data:
  spark-jars:
  prometheus-data:
  grafana-data:
  postgres-data:
  redis-data:


networks:
  data-network:
    driver: bridge
